{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Generation for image similarity using Wiener Deconvolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `wiener_deconvolution`\n",
    "Performs wiener deconvolution on a target and input image and outputs a kernal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_deconvolution(input_image: np.ndarray, target_image: np.ndarray, noise_level: float = 0.1, kernel_size: int = 15) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform Wiener deconvolution to compute the deblurring kernel.\n",
    "\n",
    "    Parameters:\n",
    "    - input_image: np.ndarray - The input (blurry) image.\n",
    "    - target_image: np.ndarray - The target (sharp) image.\n",
    "    - noise_level: float - The noise level for regularization (default is 0.1).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray - The computed deblurring kernel.\n",
    "    \"\"\"\n",
    "   # Compute FFT of input and target images\n",
    "    input_fft = fftpack.fft2(input_image)\n",
    "    target_fft = fftpack.fft2(target_image)\n",
    "    \n",
    "    # Estimate the filter in frequency domain\n",
    "    filter_fft = np.conj(input_fft) * target_fft / (np.abs(input_fft)**2 + noise_level**2)\n",
    "    \n",
    "    # Convert filter back to spatial domain\n",
    "    kernel = np.real(fftpack.ifft2(filter_fft))\n",
    "    \n",
    "    # Normalize and truncate the kernel\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    kernel = fftpack.fftshift(kernel)\n",
    "    center = kernel.shape[0] // 2\n",
    "    kernel = kernel[center - kernel_size // 2:center + kernel_size // 2 + 1,\n",
    "                    center - kernel_size // 2:center + kernel_size // 2 + 1]\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `apply_kernel`\n",
    "Applies kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernel(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    return signal.convolve2d(image, kernel, mode='same', boundary='wrap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `apply_sharpening`\n",
    "Applies sharpening to an image based on a given sharpening factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sharpening(image: np.ndarray, sharpening_factor: float):\n",
    "    \"\"\"\n",
    "    Apply sharpening to the image.\n",
    "    :param image: Input image\n",
    "    :param sharpening_factor: Factor to control the strength of sharpening (0.0 means no sharpening)\n",
    "    :return: Sharpened image\n",
    "    \"\"\"\n",
    "    # Define sharpening kernel\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5 + sharpening_factor, -1],\n",
    "                       [0, -1, 0]])\n",
    "    # Apply the kernel to the image\n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `adjust_brightness`\n",
    "Adjusts the brightness of an image based on a given brightness factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness(image: np.ndarray, brightness_factor: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adjust the brightness of the image.\n",
    "    :param image: Input image\n",
    "    :param brightness_factor: Factor by which to increase the brightness (1.0 means no change)\n",
    "    :return: Brightness adjusted image\n",
    "    \"\"\"\n",
    "    # Convert image to float32 to prevent clipping values during multiplication\n",
    "    image_float = image.astype(np.float32)\n",
    "    # Adjust brightness\n",
    "    brightened_image = image_float * brightness_factor\n",
    "    # Clip values to the range [0, 255]\n",
    "    brightened_image = np.clip(brightened_image, 0, 255)\n",
    "    # Convert back to uint8\n",
    "    return brightened_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brighten_dark_spots(image, threshold=50, brighten_factor=1.5):\n",
    "    \"\"\"\n",
    "    Brighten only the dark spots of the image.\n",
    "    :param image: Input grayscale image\n",
    "    :param threshold: Intensity threshold to identify dark spots\n",
    "    :param brighten_factor: Factor by which to brighten the dark spots\n",
    "    :return: Image with brightened dark spots\n",
    "    \"\"\"\n",
    "    # Ensure image is in float32 to prevent clipping values during multiplication\n",
    "    image_float = image.astype(np.float32)\n",
    "    \n",
    "    # Create a mask for dark spots\n",
    "    dark_spots_mask = image_float < threshold\n",
    "    \n",
    "    # Brighten dark spots\n",
    "    brightened_image = image_float.copy()\n",
    "    brightened_image[dark_spots_mask] *= brighten_factor\n",
    "    \n",
    "    # Clip values to the range [0, 255]\n",
    "    brightened_image = np.clip(brightened_image, 0, 255)\n",
    "    \n",
    "    # Convert back to uint8\n",
    "    return brightened_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images in grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "Noise level: 0.05\n",
      "Kernel size: 11\n",
      "Sharpening factor: 0.7\n",
      "Brightness factor: 1.5\n",
      "Best similarity: 0.6894429638847448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_image(input_image, target_image, noise_level, kernel_size, sharpening_factor, brightness_factor):\n",
    "    kernel = wiener_deconvolution(input_image, target_image, noise_level, kernel_size)\n",
    "    result_image = apply_kernel(input_image, kernel)\n",
    "    result_image = apply_sharpening(result_image, sharpening_factor)\n",
    "    result_image = adjust_brightness(result_image, brightness_factor)\n",
    "    return result_image\n",
    "\n",
    "def calculate_similarity(img1, img2):\n",
    "    return ssim(img1, img2)\n",
    "\n",
    "# Load images\n",
    "input_image = cv2.imread('Prostate.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "target_image = cv2.imread('good.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Ensure images are the same size\n",
    "min_shape = np.minimum(input_image.shape, target_image.shape)\n",
    "input_image = input_image[:min_shape[0], :min_shape[1]]\n",
    "target_image = target_image[:min_shape[0], :min_shape[1]]\n",
    "\n",
    "# Define parameter ranges\n",
    "noise_levels = [0.05, 0.1, 0.2]\n",
    "kernel_sizes = [11, 15, 19]\n",
    "sharpening_factors = [0.3, 0.5, 0.7]\n",
    "brightness_factors = [1.5, 2.0, 2.5]\n",
    "\n",
    "best_similarity = -np.inf\n",
    "best_params = None\n",
    "\n",
    "# Grid search\n",
    "for noise_level in noise_levels:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        for sharpening_factor in sharpening_factors:\n",
    "            for brightness_factor in brightness_factors:\n",
    "                result_image = process_image(input_image, target_image, noise_level, kernel_size, sharpening_factor, brightness_factor)\n",
    "                similarity = calculate_similarity(result_image, target_image)\n",
    "                \n",
    "                if similarity > best_similarity:\n",
    "                    best_similarity = similarity\n",
    "                    best_params = (noise_level, kernel_size, sharpening_factor, brightness_factor)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(f\"Noise level: {best_params[0]}\")\n",
    "print(f\"Kernel size: {best_params[1]}\")\n",
    "print(f\"Sharpening factor: {best_params[2]}\")\n",
    "print(f\"Brightness factor: {best_params[3]}\")\n",
    "print(f\"Best similarity: {best_similarity}\")\n",
    "\n",
    "# Generate and save the best result\n",
    "best_result = process_image(input_image, target_image, *best_params)\n",
    "cv2.imwrite(\"best_result.png\", best_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
